{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQAstXRA5Elp",
        "outputId": "1a022ed0-84a4-452c-9d1b-e5c4f9f9aa51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'small-coder'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 28 (delta 4), reused 17 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (28/28), 40.87 KiB | 6.81 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n"
          ]
        }
      ],
      "source": [
        "![ ! -f requirements.txt ] && git clone https://github.com/anudaweerasinghe/small-coder.git\n",
        "%cd /content/small-coder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gEAAaukh5Elr"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "! pip3 install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/bigcode-project/bigcode-evaluation-harness.git\n",
        "%cd bigcode-evaluation-harness"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biOzMPt4y5IY",
        "outputId": "ac12adfe-76ce-42b1-e022-17080d72f691"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bigcode-evaluation-harness'...\n",
            "remote: Enumerating objects: 4107, done.\u001b[K\n",
            "remote: Counting objects: 100% (1689/1689), done.\u001b[K\n",
            "remote: Compressing objects: 100% (487/487), done.\u001b[K\n",
            "remote: Total 4107 (delta 1360), reused 1381 (delta 1193), pack-reused 2418\u001b[K\n",
            "Receiving objects: 100% (4107/4107), 818.20 KiB | 20.98 MiB/s, done.\n",
            "Resolving deltas: 100% (2794/2794), done.\n",
            "/content/bigcode-evaluation-harness\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrdHKbyszgyy",
        "outputId": "ce3f5f57-40f3-41e2-9523-184c23592f37"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/bigcode-evaluation-harness\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from bigcode-eval==0.0.0) (4.38.2)\n",
            "Collecting accelerate>=0.13.2 (from bigcode-eval==0.0.0)\n",
            "  Downloading accelerate-0.29.2-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.4/297.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.6.1 (from bigcode-eval==0.0.0)\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate>=0.3.0 (from bigcode-eval==0.0.0)\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyext==0.7 (from bigcode-eval==0.0.0)\n",
            "  Downloading pyext-0.7.tar.gz (7.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mosestokenizer==1.0.0 (from bigcode-eval==0.0.0)\n",
            "  Downloading mosestokenizer-1.0.0-py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface_hub>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from bigcode-eval==0.0.0) (0.20.3)\n",
            "Requirement already satisfied: fsspec<2023.10.0 in /usr/local/lib/python3.10/dist-packages (from bigcode-eval==0.0.0) (2023.6.0)\n",
            "Collecting docopt (from mosestokenizer==1.0.0->bigcode-eval==0.0.0)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting openfile (from mosestokenizer==1.0.0->bigcode-eval==0.0.0)\n",
            "  Downloading openfile-0.0.7-py3-none-any.whl (2.4 kB)\n",
            "Collecting toolwrapper (from mosestokenizer==1.0.0->bigcode-eval==0.0.0)\n",
            "  Downloading toolwrapper-2.1.0.tar.gz (3.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.13.2->bigcode-eval==0.0.0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.13.2->bigcode-eval==0.0.0) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.13.2->bigcode-eval==0.0.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.13.2->bigcode-eval==0.0.0) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.13.2->bigcode-eval==0.0.0) (2.2.1+cu121)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.13.2->bigcode-eval==0.0.0) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.6.1->bigcode-eval==0.0.0) (3.13.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.6.1->bigcode-eval==0.0.0) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.6.1->bigcode-eval==0.0.0) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.6.1->bigcode-eval==0.0.0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.6.1->bigcode-eval==0.0.0) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.6.1->bigcode-eval==0.0.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.6.1->bigcode-eval==0.0.0) (4.66.2)\n",
            "Collecting xxhash (from datasets>=2.6.1->bigcode-eval==0.0.0)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets>=2.6.1->bigcode-eval==0.0.0)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.6.1->bigcode-eval==0.0.0) (3.9.3)\n",
            "Collecting responses<0.19 (from evaluate>=0.3.0->bigcode-eval==0.0.0)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.11.1->bigcode-eval==0.0.0) (4.11.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->bigcode-eval==0.0.0) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->bigcode-eval==0.0.0) (0.15.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.6.1->bigcode-eval==0.0.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.6.1->bigcode-eval==0.0.0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.6.1->bigcode-eval==0.0.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.6.1->bigcode-eval==0.0.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.6.1->bigcode-eval==0.0.0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.6.1->bigcode-eval==0.0.0) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.6.1->bigcode-eval==0.0.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.6.1->bigcode-eval==0.0.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.6.1->bigcode-eval==0.0.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.6.1->bigcode-eval==0.0.0) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.13.2->bigcode-eval==0.0.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.13.2->bigcode-eval==0.0.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.13.2->bigcode-eval==0.0.0) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate>=0.13.2->bigcode-eval==0.0.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate>=0.13.2->bigcode-eval==0.0.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate>=0.13.2->bigcode-eval==0.0.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate>=0.13.2->bigcode-eval==0.0.0)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate>=0.13.2->bigcode-eval==0.0.0)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate>=0.13.2->bigcode-eval==0.0.0)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate>=0.13.2->bigcode-eval==0.0.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate>=0.13.2->bigcode-eval==0.0.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate>=0.13.2->bigcode-eval==0.0.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate>=0.13.2->bigcode-eval==0.0.0)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate>=0.13.2->bigcode-eval==0.0.0)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.13.2->bigcode-eval==0.0.0) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate>=0.13.2->bigcode-eval==0.0.0)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.6.1->bigcode-eval==0.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.6.1->bigcode-eval==0.0.0) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.6.1->bigcode-eval==0.0.0) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.6.1->bigcode-eval==0.0.0) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate>=0.13.2->bigcode-eval==0.0.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate>=0.13.2->bigcode-eval==0.0.0) (1.3.0)\n",
            "Building wheels for collected packages: pyext, docopt, toolwrapper\n",
            "  Building wheel for pyext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyext: filename=pyext-0.7-py3-none-any.whl size=7222 sha256=5e45f78344d1c46719f1d375963b0e70d67181329310878eaec5367cd1a8cc8d\n",
            "  Stored in directory: /root/.cache/pip/wheels/09/95/a9/f3f15c5e52dec7912c332ae503e82fd680e576bf336437f002\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=e3b24e9a60532a6dcd1bc74b582a8c7eb987a5956316c7fc204be7ff54718d3a\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for toolwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for toolwrapper: filename=toolwrapper-2.1.0-py3-none-any.whl size=3336 sha256=21159318f746320d2c5c96b158bd27814d3906139f05ba63fbf0b810d2940d81\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/af/b1/99b57a06dda78fdcee86d2e22c64743f3b8df8f31cfc04baf7\n",
            "Successfully built pyext docopt toolwrapper\n",
            "Installing collected packages: toolwrapper, pyext, openfile, docopt, xxhash, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mosestokenizer, dill, responses, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, evaluate, accelerate, bigcode-eval\n",
            "  Running setup.py develop for bigcode-eval\n",
            "Successfully installed accelerate-0.29.2 bigcode-eval-0.0.0 datasets-2.18.0 dill-0.3.8 docopt-0.6.2 evaluate-0.4.1 mosestokenizer-1.0.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 openfile-0.0.7 pyext-0.7 responses-0.18.0 toolwrapper-2.1.0 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate config default\n",
        "!mv /root/.cache/huggingface/accelerate/default_config.yaml /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgZuU9OGzmhb",
        "outputId": "5f977489-903e-48de-c56b-82541681657e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accelerate configuration saved at /root/.cache/huggingface/accelerate/default_config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch  main.py \\\n",
        "  --model \"deepseek-ai/deepseek-coder-1.3b-instruct\" \\\n",
        "  --max_length_generation 1024 \\\n",
        "  --tasks humaneval \\\n",
        "  --temperature 0.2 \\\n",
        "  --n_samples 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --allow_code_execution"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRRgCeYp0rrR",
        "outputId": "e92a2e5d-6978-4a4f-e111-73391a9875b8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2024-04-13 00:21:45.402544: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-13 00:21:45.402590: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-13 00:21:45.403895: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-13 00:21:46.523923: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Selected Tasks: ['humaneval']\n",
            "Loading model in fp32\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:466: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:720: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "number of problems for this task is 164\n",
            "100% 164/164 [10:57<00:00,  4.01s/it]\n",
            "Evaluating generations...\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "{\n",
            "  \"humaneval\": {\n",
            "    \"pass@1\": 0.5975609756097561\n",
            "  },\n",
            "  \"config\": {\n",
            "    \"prefix\": \"\",\n",
            "    \"do_sample\": true,\n",
            "    \"temperature\": 0.2,\n",
            "    \"top_k\": 0,\n",
            "    \"top_p\": 0.95,\n",
            "    \"n_samples\": 1,\n",
            "    \"eos\": \"<|endoftext|>\",\n",
            "    \"seed\": 0,\n",
            "    \"model\": \"deepseek-ai/deepseek-coder-1.3b-instruct\",\n",
            "    \"modeltype\": \"causal\",\n",
            "    \"peft_model\": null,\n",
            "    \"revision\": null,\n",
            "    \"use_auth_token\": false,\n",
            "    \"trust_remote_code\": false,\n",
            "    \"tasks\": \"humaneval\",\n",
            "    \"instruction_tokens\": null,\n",
            "    \"batch_size\": 1,\n",
            "    \"max_length_generation\": 1024,\n",
            "    \"precision\": \"fp32\",\n",
            "    \"load_in_8bit\": false,\n",
            "    \"load_in_4bit\": false,\n",
            "    \"left_padding\": false,\n",
            "    \"limit\": null,\n",
            "    \"limit_start\": 0,\n",
            "    \"save_every_k_tasks\": -1,\n",
            "    \"postprocess\": true,\n",
            "    \"allow_code_execution\": true,\n",
            "    \"generation_only\": false,\n",
            "    \"load_generations_path\": null,\n",
            "    \"load_data_path\": null,\n",
            "    \"metric_output_path\": \"evaluation_results.json\",\n",
            "    \"save_generations\": false,\n",
            "    \"load_generations_intermediate_paths\": null,\n",
            "    \"save_generations_path\": \"generations.json\",\n",
            "    \"save_references\": false,\n",
            "    \"save_references_path\": \"references.json\",\n",
            "    \"prompt\": \"prompt\",\n",
            "    \"max_memory_per_gpu\": null,\n",
            "    \"check_references\": false\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch  main.py \\\n",
        "  --model \"deepseek-ai/deepseek-coder-1.3b-instruct\" \\\n",
        "  --max_length_generation 1024 \\\n",
        "  --tasks mbpp \\\n",
        "  --temperature 0.2 \\\n",
        "  --n_samples 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --allow_code_execution"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq6rDO_B4Lrg",
        "outputId": "881b57be-45af-40fd-eb93-853736565aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2024-04-13 00:35:32.025759: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-13 00:35:32.025810: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-13 00:35:32.027219: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-13 00:35:33.105846: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Selected Tasks: ['mbpp']\n",
            "Loading model in fp32\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:466: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:720: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "Downloading readme: 100% 9.06k/9.06k [00:00<00:00, 21.6MB/s]\n",
            "Downloading data: 100% 87.2k/87.2k [00:01<00:00, 47.4kB/s]\n",
            "Downloading data: 100% 116k/116k [00:01<00:00, 63.2kB/s]\n",
            "Downloading data: 100% 25.1k/25.1k [00:00<00:00, 57.3kB/s]\n",
            "Downloading data: 100% 7.88k/7.88k [00:01<00:00, 6.18kB/s]\n",
            "Generating train split: 100% 374/374 [00:00<00:00, 11328.51 examples/s]\n",
            "Generating test split: 100% 500/500 [00:00<00:00, 125270.41 examples/s]\n",
            "Generating validation split: 100% 90/90 [00:00<00:00, 31530.85 examples/s]\n",
            "Generating prompt split: 100% 10/10 [00:00<00:00, 4167.63 examples/s]\n",
            "number of problems for this task is 500\n",
            " 30% 148/500 [08:18<25:12,  4.30s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WseLbEH04VhG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}