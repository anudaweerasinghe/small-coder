{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "usOVkkbEF1MY",
        "outputId": "465c76d6-4336-4821-eef7-faa82722883f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'small-coder'...\n",
            "remote: Enumerating objects: 105, done.\u001b[K\n",
            "remote: Counting objects: 100% (105/105), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 105 (delta 50), reused 66 (delta 23), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (105/105), 533.53 KiB | 4.41 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "/content/small-coder\n"
          ]
        }
      ],
      "source": [
        "![ ! -f requirements.txt ] && git clone https://github.com/anudaweerasinghe/small-coder.git\n",
        "%cd /content/small-coder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4x1T1hL_F1MZ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "! pip3 install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NK6lUJxaF1MZ",
        "outputId": "46294d95-6011-4394-b37f-38e32e19c32e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bigcode-evaluation-harness'...\n",
            "remote: Enumerating objects: 4120, done.\u001b[K\n",
            "remote: Counting objects: 100% (1597/1597), done.\u001b[K\n",
            "remote: Compressing objects: 100% (486/486), done.\u001b[K\n",
            "remote: Total 4120 (delta 1264), reused 1292 (delta 1102), pack-reused 2523\u001b[K\n",
            "Receiving objects: 100% (4120/4120), 820.40 KiB | 7.89 MiB/s, done.\n",
            "Resolving deltas: 100% (2803/2803), done.\n",
            "/content/small-coder/bigcode-evaluation-harness\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/bigcode-project/bigcode-evaluation-harness.git\n",
        "%cd bigcode-evaluation-harness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WT1d1UXBF1Ma"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SWcMM8IzF1Ma",
        "outputId": "47147373-bd3d-41cb-e423-fdace53190df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accelerate configuration saved at /root/.cache/huggingface/accelerate/default_config.yaml\n"
          ]
        }
      ],
      "source": [
        "!accelerate config default\n",
        "!mv /root/.cache/huggingface/accelerate/default_config.yaml /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pgx2sYsLF1Ma",
        "outputId": "33eaf702-7a30-424d-d0ed-3b0bd73f32bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2024-04-20 20:01:20.728074: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-20 20:01:20.728127: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-20 20:01:20.729650: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-20 20:01:21.842993: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Selected Tasks: ['humaneval']\n",
            "Loading model in fp32\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:466: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "config.json: 100% 685/685 [00:00<00:00, 4.39MB/s]\n",
            "pytorch_model.bin: 100% 2.20G/2.20G [00:32<00:00, 67.5MB/s]\n",
            "generation_config.json: 100% 124/124 [00:00<00:00, 740kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:720: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "tokenizer_config.json: 100% 1.29k/1.29k [00:00<00:00, 5.66MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 14.6MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 14.9MB/s]\n",
            "special_tokens_map.json: 100% 437/437 [00:00<00:00, 2.86MB/s]\n",
            "Downloading readme: 100% 6.52k/6.52k [00:00<00:00, 23.5MB/s]\n",
            "Downloading data: 100% 83.9k/83.9k [00:00<00:00, 444kB/s]\n",
            "Generating test split: 100% 164/164 [00:00<00:00, 5593.77 examples/s]\n",
            "number of problems for this task is 164\n",
            "100% 164/164 [15:48<00:00,  5.78s/it]\n",
            "Evaluating generations...\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "{\n",
            "  \"humaneval\": {\n",
            "    \"pass@1\": 0.11585365853658537\n",
            "  },\n",
            "  \"config\": {\n",
            "    \"prefix\": \"\",\n",
            "    \"do_sample\": true,\n",
            "    \"temperature\": 0.2,\n",
            "    \"top_k\": 0,\n",
            "    \"top_p\": 0.95,\n",
            "    \"n_samples\": 1,\n",
            "    \"eos\": \"<|endoftext|>\",\n",
            "    \"seed\": 0,\n",
            "    \"model\": \"shreeyak/finetuned-tinyllama-1.1B\",\n",
            "    \"modeltype\": \"causal\",\n",
            "    \"peft_model\": null,\n",
            "    \"revision\": null,\n",
            "    \"use_auth_token\": false,\n",
            "    \"trust_remote_code\": false,\n",
            "    \"tasks\": \"humaneval\",\n",
            "    \"instruction_tokens\": null,\n",
            "    \"batch_size\": 1,\n",
            "    \"max_length_generation\": 1024,\n",
            "    \"precision\": \"fp32\",\n",
            "    \"load_in_8bit\": false,\n",
            "    \"load_in_4bit\": false,\n",
            "    \"left_padding\": false,\n",
            "    \"limit\": null,\n",
            "    \"limit_start\": 0,\n",
            "    \"save_every_k_tasks\": -1,\n",
            "    \"postprocess\": true,\n",
            "    \"allow_code_execution\": true,\n",
            "    \"generation_only\": false,\n",
            "    \"load_generations_path\": null,\n",
            "    \"load_data_path\": null,\n",
            "    \"metric_output_path\": \"evaluation_results.json\",\n",
            "    \"save_generations\": false,\n",
            "    \"load_generations_intermediate_paths\": null,\n",
            "    \"save_generations_path\": \"generations.json\",\n",
            "    \"save_references\": false,\n",
            "    \"save_references_path\": \"references.json\",\n",
            "    \"prompt\": \"prompt\",\n",
            "    \"max_memory_per_gpu\": null,\n",
            "    \"check_references\": false\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "!accelerate launch  main.py \\\n",
        "  --model \"shreeyak/finetuned-tinyllama-1.1B\" \\\n",
        "  --max_length_generation 1024 \\\n",
        "  --tasks humaneval \\\n",
        "  --temperature 0.2 \\\n",
        "  --n_samples 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --allow_code_execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EhnzRxJQF1Ma",
        "outputId": "422e80d4-4ea2-4724-f26f-8d80362ca44d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2024-04-20 20:19:54.741680: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-20 20:19:54.741733: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-20 20:19:54.743254: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/small-coder/bigcode-evaluation-harness/main.py\", line 18, in <module>\n",
            "    from bigcode_eval.evaluator import Evaluator\n",
            "  File \"/content/small-coder/bigcode-evaluation-harness/bigcode_eval/evaluator.py\", line 9, in <module>\n",
            "    from bigcode_eval import tasks\n",
            "  File \"/content/small-coder/bigcode-evaluation-harness/bigcode_eval/tasks/__init__.py\", line 4, in <module>\n",
            "    from . import (apps, codexglue_code_to_text, codexglue_text_to_text, conala,\n",
            "  File \"/content/small-coder/bigcode-evaluation-harness/bigcode_eval/tasks/apps.py\", line 12, in <module>\n",
            "    from evaluate import load\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/evaluate/__init__.py\", line 29, in <module>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/subprocess.py\", line 1209, in wait\n",
            "    from .evaluation_suite import EvaluationSuite\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/evaluate/evaluation_suite/__init__.py\", line 10, in <module>\n",
            "    return self._wait(timeout=timeout)\n",
            "  File \"/usr/lib/python3.10/subprocess.py\", line 1959, in _wait\n",
            "    from ..evaluator import evaluator\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/evaluate/evaluator/__init__.py\", line 17, in <module>\n",
            "    from transformers.pipelines import SUPPORTED_TASKS as SUPPORTED_PIPELINE_TASKS\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/__init__.py\", line 26, in <module>\n",
            "    (pid, sts) = self._try_wait(0)\n",
            "  File \"/usr/lib/python3.10/subprocess.py\", line 1917, in _try_wait\n",
            "    (pid, sts) = os.waitpid(self.pid, wait_flags)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py\", line 46, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 1075, in launch_command\n",
            "    from ..image_processing_utils import BaseImageProcessor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/image_processing_utils.py\", line 28, in <module>\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 678, in simple_launcher\n",
            "    process.wait()\n",
            "  File \"/usr/lib/python3.10/subprocess.py\", line 1222, in wait\n",
            "    self._wait(timeout=sigint_timeout)\n",
            "  File \"/usr/lib/python3.10/subprocess.py\", line 1953, in _wait\n",
            "    time.sleep(delay)\n",
            "KeyboardInterrupt\n",
            "    from .image_transforms import center_crop, normalize, rescale\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/image_transforms.py\", line 47, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\", line 48, in <module>\n",
            "    from tensorflow._api.v2 import __internal__\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 8, in <module>\n",
            "    from tensorflow._api.v2.__internal__ import autograph\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\", line 8, in <module>\n",
            "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/core/ag_ctx.py\", line 21, in <module>\n",
            "    from tensorflow.python.autograph.utils import ag_logging\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/utils/__init__.py\", line 17, in <module>\n",
            "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/utils/context_managers.py\", line 19, in <module>\n",
            "    from tensorflow.python.framework import ops\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\", line 45, in <module>\n",
            "    from tensorflow.python.eager import context\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\", line 37, in <module>\n",
            "    from tensorflow.python.eager import execute\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n",
            "    from tensorflow.python.framework import dtypes\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/dtypes.py\", line 794, in <module>\n",
            "    def as_dtype(type_value):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/tf_export.py\", line 343, in __call__\n",
            "    _, undecorated_func = tf_decorator.unwrap(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/tf_decorator.py\", line 272, in unwrap\n",
            "    def unwrap(maybe_tf_decorator):\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!accelerate launch  main.py \\\n",
        "  --model \"shreeyak/finetuned-tinyllama-1.1B\" \\\n",
        "  --max_length_generation 2048 \\\n",
        "  --tasks mbpp \\\n",
        "  --temperature 0.2 \\\n",
        "  --n_samples 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --allow_code_execution"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DuDl61ftKh1g"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}