= Introduction
// Very succinctly summarize all aspects of your project proposal.
Small models that perform well on specific, vertical tasks are very important for most scalable product use-cases. We want to explore building a small model for such a vertical task - Python code generation. We chose Python code generation because it has (1) high quality datasets, (2) pre-trained large models that perform well, and (3) sufficient difficulty to allow for some interesting findings. \
\
We will begin by replicating the baseline performance of a state-of-the-art small model (`DeepSeek-Coder 1.5B`)@guo2024deepseek on the HumanEval  @chen2021codex and Mostly Basic Python Programs (MBPP) @austin2021program datasets. We will then attempt to build a much smaller model (\~2B parameters) that can run locally via (1) supervised fine-tuning, (2) knowledge distillation, and (3) external tool integration (Python interpreter, API Doc Search, etc.). 